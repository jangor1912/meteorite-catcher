{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images_dir = Path('../data/images/dim-meteorite-full-res')\n",
    "\n",
    "first_image = images_dir / \"179.png\"\n",
    "second_image = images_dir / \"180.png\""
   ],
   "id": "e08537e4f684fa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx = 56\n",
    "\n",
    "img1_rgb = cv2.cvtColor(cv2.imread(str(first_image.absolute())), cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(cv2.imread(str(second_image.absolute())), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# convert to grayscale\n",
    "img1 = cv2.cvtColor(img1_rgb, cv2.COLOR_RGB2GRAY)\n",
    "img2 = cv2.cvtColor(img2_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# compute grayscale image difference\n",
    "grayscale_diff = cv2.subtract(img2, img1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(25, 25))\n",
    "ax[0].imshow(img1_rgb)\n",
    "ax[0].set_title('Frame 1')\n",
    "ax[1].imshow(img2_rgb)\n",
    "ax[1].set_title('Frame 2')\n",
    "ax[2].imshow(grayscale_diff*50) # scale the frame difference to show the noise\n",
    "ax[2].set_title('Frame Difference')"
   ],
   "id": "372b249ac4a91fe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_mask(frame1, frame2, kernel=np.array((9,9), dtype=np.uint8)):\n",
    "    \"\"\" Obtains image mask\n",
    "        Inputs: \n",
    "            frame1 - Grayscale frame at time t\n",
    "            frame2 - Grayscale frame at time t + 1\n",
    "            kernel - (NxN) array for Morphological Operations\n",
    "        Outputs: \n",
    "            mask - Thresholded mask for moving pixels\n",
    "        \"\"\"\n",
    "    frame_diff = cv2.subtract(frame2, frame1)\n",
    "\n",
    "    # blur the frame difference\n",
    "    frame_diff = cv2.medianBlur(frame_diff, 3)\n",
    "    \n",
    "    mask = cv2.adaptiveThreshold(frame_diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY_INV, 11, 3)\n",
    "\n",
    "    mask = cv2.medianBlur(mask, 3)\n",
    "\n",
    "    # morphological operations\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    return mask"
   ],
   "id": "b04ab27a80c21680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = np.array((9,9), dtype=np.uint8)\n",
    "mask = get_mask(img1, img2, kernel)\n",
    "\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(\"Motion Mask\");"
   ],
   "id": "7a35556afaa0a3bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_contour_detections(mask, thresh=400):\n",
    "    \"\"\" Obtains initial proposed detections from contours discoverd on the mask. \n",
    "        Scores are taken as the bbox area, larger is higher.\n",
    "        Inputs:\n",
    "            mask - thresholded image mask\n",
    "            thresh - threshold for contour size\n",
    "        Outputs:\n",
    "            detectons - array of proposed detection bounding boxes and scores [[x1,y1,x2,y2,s]]\n",
    "        \"\"\"\n",
    "    # get mask contours\n",
    "    contours, _ = cv2.findContours(mask, \n",
    "                                   cv2.RETR_EXTERNAL, # cv2.RETR_TREE, \n",
    "                                   cv2.CHAIN_APPROX_TC89_L1)\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        area = w*h\n",
    "        if area > thresh: # hyperparameter\n",
    "            detections.append([x,y,x+w,y+h, area])\n",
    "\n",
    "    return np.array(detections)"
   ],
   "id": "2701a14b630bfad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "detections = get_contour_detections(mask, thresh=2)\n",
    "\n",
    "bboxes = []\n",
    "scores = []\n",
    "\n",
    "# separate bboxes and scores\n",
    "if len(detections) > 0:\n",
    "    bboxes = detections[:, :4]\n",
    "    scores = detections[:, -1]\n",
    "\n",
    "for box in bboxes:\n",
    "    x1,y1,x2,y2 = box\n",
    "    cv2.rectangle(mask_rgb, (x1,y1), (x2,y2), (255,0,0), 3)\n",
    "\n",
    "plt.imshow(mask_rgb)\n",
    "plt.title(\"Detected Movers\");"
   ],
   "id": "8fdb53ec0a9af0e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_iou(box1, box2):\n",
    "    \"\"\" Obtains Intersection over union (IOU) of 2 bounding boxes\n",
    "        Inputs are in the form of:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "        \"\"\"\n",
    "    x11, y11, x21, y21 = box1\n",
    "    x12, y12, x22, y22 = box2\n",
    "\n",
    "    # get box points of intersection\n",
    "    xi1 = max(x11, x12) # top left\n",
    "    yi1 = max(y11, y12)\n",
    "    xi2 = min(x21, x22) # bottom right\n",
    "    yi2 = min(y21, y22)\n",
    "\n",
    "    # compute intersectional area\n",
    "    inter_area = max((xi2 - xi1 + 1), 0) * max((yi2 - yi1 + 1), 0)\n",
    "    if inter_area == 0:\n",
    "        return inter_area\n",
    "\n",
    "    # compute box areas\n",
    "    box1_area = (x21 - x11 + 1) * (y21 - y11 + 1)\n",
    "    box2_area = (x22 - x12 + 1) * (y22 - y12 + 1)\n",
    "\n",
    "    # return iou\n",
    "    return inter_area / (box1_area + box2_area - inter_area)\n",
    "\n",
    "\n",
    "def get_inter_area(box1, box2):\n",
    "    \"\"\"\n",
    "    Obtains bounding box for intersection area of two boundning boxes\n",
    "    Inputs are in the form of:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "    \"\"\"\n",
    "    x11, y11, x21, y21 = box1\n",
    "    x12, y12, x22, y22 = box2\n",
    "\n",
    "    # get box points of intersection\n",
    "    xi1 = max(x11, x12) # top left\n",
    "    yi1 = max(y11, y12)\n",
    "    xi2 = min(x21, x22) # bottom right\n",
    "    yi2 = min(y21, y22)\n",
    "\n",
    "    # compute intersectional area\n",
    "    inter_area = max((xi2 - xi1 + 1), 0) * max((yi2 - yi1 + 1), 0)\n",
    "    if inter_area == 0:\n",
    "        return 0, 0, 0, 0\n",
    "        \n",
    "    return xi1, yi1, xi2, yi2"
   ],
   "id": "3ae451281a7550b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_rgb_iou = mask_rgb.copy()\n",
    "\n",
    "# only compare unique cases\n",
    "idx_1, idx_2 = np.triu_indices(len(bboxes), k=1)\n",
    "\n",
    "for i in range(len(idx_1)):\n",
    "    b1 = bboxes[idx_1[i]].tolist()\n",
    "    b2 = bboxes[idx_2[i]].tolist()\n",
    "    iou = compute_iou(b1, b2)\n",
    "    if iou > 0:\n",
    "        # print(idx, np.round(iou,2))\n",
    "\n",
    "        # draw intersection\n",
    "        x1, y1, x2, y2 = get_inter_area(b1, b2)\n",
    "        cv2.rectangle(mask_rgb_iou, (x1,y1), (x2,y2), (0,255,0), 3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "ax[0].imshow(mask_rgb)\n",
    "ax[0].set_title('Detected Movers')\n",
    "ax[1].imshow(mask_rgb_iou)\n",
    "ax[1].set_title('Detected Movers with Overlapping bboxes');"
   ],
   "id": "703ee7220a2ab120",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def remove_contained_bboxes(boxes):\n",
    "    \"\"\" Removes all smaller boxes that are contained within larger boxes.\n",
    "        Requires bboxes to be sorted by area (score)\n",
    "        Inputs:\n",
    "            boxes - array bounding boxes sorted (descending) by area \n",
    "                    [[x1,y1,x2,y2]]\n",
    "        Outputs:\n",
    "            keep - indexes of bounding boxes that are not entirely contained \n",
    "                   in another box\n",
    "        \"\"\"\n",
    "    check_array = np.array([True, True, False, False])\n",
    "    keep = list(range(0, len(boxes)))\n",
    "    for i in keep: # range(0, len(bboxes)):\n",
    "        for j in range(0, len(boxes)):\n",
    "            # check if box j is completely contained in box i\n",
    "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == check_array):\n",
    "                try:\n",
    "                    keep.remove(j)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return keep\n",
    "\n",
    "\n",
    "def non_max_suppression(boxes, scores, threshold=1e-1):\n",
    "    \"\"\"\n",
    "    Perform non-max suppression on a set of bounding boxes and corresponding scores.\n",
    "    Inputs:\n",
    "        boxes: a list of bounding boxes in the format [xmin, ymin, xmax, ymax]\n",
    "        scores: a list of corresponding scores \n",
    "        threshold: the IoU (intersection-over-union) threshold for merging bounding boxes\n",
    "    Outputs:\n",
    "        boxes - non-max suppressed boxes\n",
    "    \"\"\"\n",
    "    # Sort the boxes by score in descending order\n",
    "    boxes = boxes[np.argsort(scores)[::-1]]\n",
    "\n",
    "    # remove all contained bounding boxes and get ordered index\n",
    "    order = remove_contained_bboxes(boxes)\n",
    "\n",
    "    keep = []\n",
    "    while order:\n",
    "        i = order.pop(0)\n",
    "        keep.append(i)\n",
    "        for j in order:\n",
    "            # Calculate the IoU between the two boxes\n",
    "            intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
    "                           max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
    "            union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
    "                    (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
    "            iou = intersection / union\n",
    "\n",
    "            # Remove boxes with IoU greater than the threshold\n",
    "            if iou > threshold:\n",
    "                order.remove(j)\n",
    "                \n",
    "    return boxes[keep]"
   ],
   "id": "1f691976f2069705",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%timeit nms_bboxes = non_max_suppression(bboxes, scores, threshold=0.1)",
   "id": "8963db22de99d56e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def non_max_suppression_2(boxes, scores, threshold=1e-1):\n",
    "    \"\"\"\n",
    "    Perform non-max suppression on a set of bounding boxes and corresponding scores.\n",
    "    NOTE: Eventhough we only go through 2 loops here, this way is more complicated and slower!\n",
    "    Inputs:\n",
    "        boxes: a list of bounding boxes in the format [xmin, ymin, xmax, ymax]\n",
    "        scores: a list of corresponding scores \n",
    "        threshold: the IoU (intersection-over-union) threshold for merging bounding boxes\n",
    "    Outputs:\n",
    "        boxes - non-max suppressed boxes\n",
    "    \"\"\"\n",
    "    # Sort the boxes by score in descending order\n",
    "    boxes = boxes[np.argsort(scores)[::-1]]\n",
    "\n",
    "    keep = list(range(0, len(boxes)))\n",
    "    for i in keep:\n",
    "        for j in range(0, len(boxes)):\n",
    "            # check if box j is completely contained in box i\n",
    "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == np.array([True, True, False, False])):\n",
    "                try:\n",
    "                    keep.remove(j)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            # if no overlap check IOU threshold\n",
    "            else:\n",
    "                # Calculate the IoU between the two boxes\n",
    "                intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
    "                            max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
    "                union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
    "                        (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
    "                iou = intersection / union\n",
    "\n",
    "                # Remove boxes with IoU greater than the threshold\n",
    "                # ensure that we don't remove larger boxes by checking (j > i)\n",
    "                if (iou > threshold) and (j > i):\n",
    "                    try:\n",
    "                        keep.remove(j)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "    return boxes[keep]"
   ],
   "id": "68b2fff63058b6a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%timeit nms_bboxes = non_max_suppression_2(bboxes, scores, threshold=0.1)",
   "id": "c47a2935089b51ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nms_bboxes = non_max_suppression_2(bboxes, scores, threshold=0.1)\n",
    "len(bboxes), len(nms_bboxes)"
   ],
   "id": "951ac90959b269cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_rgb_detections = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "for det in nms_bboxes:\n",
    "    x1, y1, x2, y2 = det\n",
    "    cv2.rectangle(mask_rgb_detections, (x1,y1), (x2,y2), (255,0,0), 3)"
   ],
   "id": "4acf4bdc8bad3bb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(mask_rgb_detections)\n",
    "plt.title(\"Non-Max Suppressed Bounding Boxes\");"
   ],
   "id": "a00f765d1ef1372f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_detections(frame1, frame2, bbox_thresh=400, nms_thresh=1e-3, mask_kernel=np.array((9,9), dtype=np.uint8)):\n",
    "    \"\"\" Main function to get detections via Frame Differencing\n",
    "        Inputs:\n",
    "            frame1 - Grayscale frame at time t\n",
    "            frame2 - Grayscale frame at time t + 1\n",
    "            bbox_thresh - Minimum threshold area for declaring a bounding box \n",
    "            nms_thresh - IOU threshold for computing Non-Maximal Supression\n",
    "            mask_kernel - kernel for morphological operations on motion mask\n",
    "        Outputs:\n",
    "            detections - list with bounding box locations of all detections\n",
    "                bounding boxes are in the form of: (xmin, ymin, xmax, ymax)\n",
    "        \"\"\"\n",
    "    # get image mask for moving pixels\n",
    "    mask = get_mask(frame1, frame2, mask_kernel)\n",
    "\n",
    "    # get initially proposed detections from contours\n",
    "    detections = get_contour_detections(mask, bbox_thresh)\n",
    "\n",
    "    # separate bboxes and scores\n",
    "    if len(detections) > 0:\n",
    "        bboxes = detections[:, :4]\n",
    "        scores = detections[:, -1]\n",
    "\n",
    "        # perform Non-Maximal Supression on initial detections\n",
    "        return non_max_suppression(bboxes, scores, nms_thresh)\n",
    "    return []"
   ],
   "id": "167bba30df9f02be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def draw_bboxes(frame, detections):\n",
    "    for det in detections:\n",
    "        x1,y1,x2,y2 = det\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 3)\n",
    "        \n",
    "def draw_tracks(frame, tracks):\n",
    "    for det in tracks:\n",
    "        x1, y1, x2, y2, _ = det\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (int(x1),int(y1)), \n",
    "            (int(x2),int(y2)), \n",
    "            (0,255,0), 3\n",
    "        )\n",
    "\n",
    "\n",
    "def create_gif_from_images(save_path : str, image_path : str, ext : str) -> None:\n",
    "    ''' creates a GIF from a folder of images\n",
    "        Inputs:\n",
    "            save_path - path to save GIF\n",
    "            image_path - path where images are located\n",
    "            ext - extension of the images\n",
    "        Outputs:\n",
    "            None\n",
    "    '''\n",
    "    ext = ext.replace('.', '')\n",
    "    image_paths = sorted(glob(os.path.join(image_path, f'*.{ext}')))\n",
    "    image_paths.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "    pil_images = [Image.open(im_path) for im_path in image_paths]\n",
    "\n",
    "    pil_images[0].save(save_path, format='GIF', append_images=pil_images,\n",
    "                       save_all=True, duration=50, loop=0)"
   ],
   "id": "3de40394acef3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "image_paths = sorted(glob(f\"{images_dir}/*.jpg\"), key=lambda x:float(re.findall(r\"(\\d+)\",x)[0]))\n",
    "\n",
    "output_directory = images_dir / \"output\"\n",
    "if output_directory.exists():\n",
    "    shutil.rmtree(str(output_directory))\n",
    "output_directory.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "73e230122dff0612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx in range(1, len(image_paths)):\n",
    "    # read frames\n",
    "    frame1_bgr = cv2.imread(image_paths[idx - 1])\n",
    "    frame2_bgr = cv2.imread(image_paths[idx])\n",
    "\n",
    "    # get detections\n",
    "    detections = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                bbox_thresh=2,\n",
    "                                nms_thresh=1e-4)\n",
    "\n",
    "\n",
    "    # draw bounding boxes on frame\n",
    "    draw_bboxes(frame2_bgr, detections)\n",
    "\n",
    "    # save image for GIF\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(frame2_bgr)\n",
    "    plt.axis('off')\n",
    "    fig.savefig(f\"{output_directory}/frame_{idx}.png\")\n",
    "    plt.close()"
   ],
   "id": "80c16f94ab85554",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_gif_from_images('frame_differencing_intro.gif', str(output_directory), '.png')",
   "id": "e1efe7066206dd52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try using IOU tracker",
   "id": "42eb32b8baf67b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    x_min: int\n",
    "    y_min: int\n",
    "    x_max: int\n",
    "    y_max: int\n",
    "    \n",
    "    @classmethod\n",
    "    def from_numpy(cls, array: np.array) -> \"BoundingBox\":\n",
    "        return cls(\n",
    "            x_min=int(array[0]),\n",
    "            y_min=int(array[1]),\n",
    "            x_max=int(array[2]),\n",
    "            y_max=int(array[3])\n",
    "        )\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(f\"{self.x_min},{self.y_min},{self.x_max},{self.y_max}\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"BBox [[{self.x_min}, {self.y_min}], [{self.x_max}, {self.y_max}]]\""
   ],
   "id": "85bf50cb4f1e0403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images_dir = Path('../data/images/dim-meteorite-full-res')\n",
    "\n",
    "first_image = images_dir / \"179.png\"\n",
    "second_image = images_dir / \"180.png\"\n",
    "third_image = images_dir / \"181.png\""
   ],
   "id": "bdaf251bc7be9005",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frame1_bgr = cv2.imread(str(first_image))\n",
    "frame2_bgr = cv2.imread(str(second_image))\n",
    "frame3_bgr = cv2.imread(str(third_image))"
   ],
   "id": "798c7ce2cc746ec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get detections\n",
    "detections = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            bbox_thresh=2,\n",
    "                            nms_thresh=1e-4)"
   ],
   "id": "c3d57c47f5e92b63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "detections",
   "id": "cd17c8cf091082ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sortedcontainers import SortedKeyList\n",
    "\n",
    "a = SortedKeyList([(9,1), (1,3), (10, 4), (3, 5)], key=lambda x: x[0])"
   ],
   "id": "4d8b921552112578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "e75f2d42a1f89983",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a[:a.bisect_key_right(3)]",
   "id": "3501f39970f7e782",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IOUTracker:\n",
    "    iou_threshold: float = 0.1\n",
    "    sigma_low: float = 0.1\n",
    "    sigma_high: float = 0.1\n",
    "    min_track_length: int = 10\n",
    "    tracks: list = field(default_factory=list, init=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_iou(box1: BoundingBox, box2: BoundingBox) -> float:\n",
    "        x11, y11, x21, y21 = box1.x_min, box1.y_min, box1.x_max, box1.y_max\n",
    "        x12, y12, x22, y22 = box2.x_min, box2.y_min, box2.x_max, box2.y_max\n",
    "    \n",
    "        # get box points of intersection\n",
    "        xi1 = max(x11, x12) # top left\n",
    "        yi1 = max(y11, y12)\n",
    "        xi2 = min(x21, x22) # bottom right\n",
    "        yi2 = min(y21, y22)\n",
    "    \n",
    "        # compute intersectional area\n",
    "        inter_area = max((xi2 - xi1 + 1), 0) * max((yi2 - yi1 + 1), 0)\n",
    "        if inter_area == 0:\n",
    "            return inter_area\n",
    "    \n",
    "        # compute box areas\n",
    "        box1_area = (x21 - x11 + 1) * (y21 - y11 + 1)\n",
    "        box2_area = (x22 - x12 + 1) * (y22 - y12 + 1)\n",
    "    \n",
    "        # return iou\n",
    "        return inter_area / (box1_area + box2_area - inter_area)\n",
    "    \n",
    "    def track(\n",
    "            self, \n",
    "            frame_1_bboxes: list[BoundingBox],\n",
    "            frame_2_bboxes: list[BoundingBox],\n",
    "            sigma_iou: float = 0.1\n",
    "    ) -> list:\n",
    "        tracks = []\n",
    "        \n",
    "        # print(f\"First frame has {len(frame_1_bboxes)} bboxes\")\n",
    "        # print(f\"Second frame has {len(frame_2_bboxes)} bboxes\")\n",
    "    \n",
    "        sorted_by_x_min_frame_2_bboxes = SortedKeyList(frame_2_bboxes, key=lambda x: x.x_min)\n",
    "        sorted_by_y_min_frame_2_bboxes = SortedKeyList(frame_2_bboxes, key=lambda x: x.y_min)\n",
    "        sorted_by_x_max_frame_2_bboxes = SortedKeyList(frame_2_bboxes, key=lambda x: x.x_max)\n",
    "        sorted_by_y_max_frame_2_bboxes = SortedKeyList(frame_2_bboxes, key=lambda x: x.y_max)\n",
    "        \n",
    "        for bbox_1 in frame_1_bboxes:\n",
    "            best_match_score = 0\n",
    "            best_match_bbox = None\n",
    "            \n",
    "            # print(f\"Finding matches for {bbox_1}\")\n",
    "            \n",
    "            # only consider bboxes that have intersection\n",
    "            bboxes_with_proper_x_min =  sorted_by_x_min_frame_2_bboxes[\n",
    "                      :sorted_by_x_min_frame_2_bboxes.bisect_key_right(bbox_1.x_max)]\n",
    "            bboxes_with_proper_x_max =  sorted_by_x_max_frame_2_bboxes[\n",
    "                      sorted_by_x_max_frame_2_bboxes.bisect_key_left(bbox_1.x_min):]\n",
    "            bboxes_with_proper_y_min =  sorted_by_y_min_frame_2_bboxes[\n",
    "                      :sorted_by_y_min_frame_2_bboxes.bisect_key_right(bbox_1.y_max)]\n",
    "            bboxes_with_proper_y_max =  sorted_by_y_max_frame_2_bboxes[\n",
    "                      sorted_by_y_max_frame_2_bboxes.bisect_key_left(bbox_1.y_min):]\n",
    "            \n",
    "            # print(f\"There are {len(bboxes_with_proper_x_min)} bboxes with proper x-min.\")\n",
    "            # print(f\"There are {len(bboxes_with_proper_x_max)} bboxes with proper x-max.\")\n",
    "            # print(f\"There are {len(bboxes_with_proper_y_min)} bboxes with proper y-min.\")\n",
    "            # print(f\"There are {len(bboxes_with_proper_y_max)} bboxes with proper y-max.\")\n",
    "            \n",
    "            matching_bboxes = set(bboxes_with_proper_x_min).intersection(bboxes_with_proper_x_max)\n",
    "            matching_bboxes = matching_bboxes.intersection(bboxes_with_proper_y_min)\n",
    "            matching_bboxes = matching_bboxes.intersection(bboxes_with_proper_y_max)\n",
    "            \n",
    "            # print(f\"There are {len(matching_bboxes)} bboxes that fulfills all the criteria\")\n",
    "            \n",
    "            for bbox_2 in matching_bboxes:\n",
    "                iou_score = self.compute_iou(bbox_1, bbox_2)\n",
    "                if iou_score > best_match_score:\n",
    "                    best_match_bbox = bbox_2\n",
    "                    best_match_score = iou_score\n",
    "            \n",
    "            if best_match_bbox is not None and best_match_score >= sigma_iou:\n",
    "                tracks.append(best_match_bbox)\n",
    "        return tracks"
   ],
   "id": "c6558dcfab89514b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "detections_1 = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            bbox_thresh=2,\n",
    "                            nms_thresh=1e-4)\n",
    "detections_2 = get_detections(cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            cv2.cvtColor(frame3_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                            bbox_thresh=2,\n",
    "                            nms_thresh=1e-4)"
   ],
   "id": "1c3cd256fef00b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "detections_1_bboxes = [BoundingBox.from_numpy(bbox) for bbox in detections_1]\n",
    "detections_2_bboxes = [BoundingBox.from_numpy(bbox) for bbox in detections_2]"
   ],
   "id": "4c0c76bdb6430132",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tracker = IOUTracker(iou_threshold=0.2)\n",
    "tracker.track(detections_1_bboxes, detections_2_bboxes)"
   ],
   "id": "362a2d33b5b131eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tracker = IOUTracker(iou_threshold=0.2)\n",
    "%timeit tracker.track(detections_1_bboxes, detections_2_bboxes)"
   ],
   "id": "792f7067acfcdd20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class FrameRegions:\n",
    "    frame_resolution: tuple[int, int]\n",
    "    region_resolution: int\n",
    "    _regions: np.array\n",
    "    \n",
    "    def _generate_regions(self) -> None:\n",
    "        frame_width, frame_height = self.frame_resolution\n",
    "        \n",
    "        x_regions_number = frame_width // self.region_resolution\n",
    "        if frame_width % self.region_resolution != 0:\n",
    "            x_regions_number += 1\n",
    "            \n",
    "        y_regions_number = frame_height // self.region_resolution\n",
    "        if frame_height % self.region_resolution != 0:\n",
    "            y_regions_number += 1\n",
    "            \n",
    "        self._regions = np.zeros((x_regions_number, y_regions_number, 4), dtype=np.uint8)\n",
    "        \n",
    "        for x_region in range(x_regions_number):\n",
    "            for y_region in range(y_regions_number):\n",
    "                x_min = x_region * self.region_resolution\n",
    "                x_max = x_min + self.region_resolution\n",
    "                if x_max >= self.frame_resolution[0]:\n",
    "                    x_max = self.frame_resolution[0] - 1\n",
    "            \n",
    "                y_min = y_region * self.region_resolution\n",
    "                y_max = y_min + self.region_resolution\n",
    "                if y_max >= self.frame_resolution[1]:\n",
    "                    y_max = self.frame_resolution[1] - 1\n",
    "                    \n",
    "                self._regions[x_region][y_region][0] = x_min\n",
    "                self._regions[x_region][y_region][1] = y_min\n",
    "                self._regions[x_region][y_region][2] = x_max\n",
    "                self._regions[x_region][y_region][3] = y_max\n",
    "        \n",
    "    def get_regions_of_bbox(self, bbox: BoundingBox) -> list[BoundingBox]:\n",
    "        x_region_min, x_region_max, y_region_min, y_region_max = 0, 0, 0, 0\n",
    "        \n",
    "        for x_region_index in range(len(self._regions)):\n",
    "            for y_region_index in range(len(self._regions[x_region_index])):\n",
    "                if bbox.x_min >= self._regions[x_region_index][y_region_index][0]:\n",
    "                    x_region_min = x_region_index\n",
    "                    \n",
    "                if bbox.y_min >= self._regions[x_region_index][y_region_index][1]:\n",
    "                    y_region_min = y_region_index\n",
    "                \n",
    "                if bbox.x_max <= self._regions[x_region_index][y_region_index][2]:\n",
    "                    x_region_max = x_region_index\n",
    "                \n",
    "                if bbox.y_max <= self._regions[x_region_index][y_region_index][3]:\n",
    "                    y_region_max = y_region_index\n",
    "        \n",
    "        "
   ],
   "id": "1c6498717465d075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def iou_tracker(frame_1_bboxes, frame_2_bboxes, sigma_iou=0.1):\n",
    "    tracks = []\n",
    "    \n",
    "    for bbox_1 in frame_1_bboxes:\n",
    "        \n",
    "        best_match_score = 0\n",
    "        best_match_bbox = None\n",
    "        best_match_index = 0\n",
    "        for i, bbox_2 in enumerate(frame_2_bboxes):\n",
    "            iou_score = compute_iou(bbox_1, bbox_2)\n",
    "            if iou_score > best_match_score:\n",
    "                best_match_bbox = bbox_2\n",
    "                best_match_score = iou_score\n",
    "                best_match_index = i\n",
    "        \n",
    "        if best_match_bbox is not None and best_match_score >= sigma_iou:\n",
    "            tracks.append(best_match_bbox)\n",
    "            frame_2_bboxes = np.delete(frame_2_bboxes, best_match_index, axis=0)\n",
    "    return tracks"
   ],
   "id": "b63b1df0d9f87460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def track_iou(dets, sigma_l, sigma_h, sigma_iou, t_min):\n",
    "    \"\"\"\n",
    "    Simple IOU based inference.\n",
    "    See \"High-Speed Tracking-by-Detection Without Using Image Information by E. Bochinski, V. Eiselein, T. Sikora\" for\n",
    "    more information.\n",
    "\n",
    "    Args:\n",
    "         detections (list): list of detections per frame, usually generated by util.load_mot\n",
    "         sigma_l (float): low detection threshold.\n",
    "         sigma_h (float): high detection threshold.\n",
    "         sigma_iou (float): IOU threshold.\n",
    "         t_min (float): minimum track length in frames.\n",
    "\n",
    "    Returns:\n",
    "        list: list of tracks.\n",
    "    \"\"\"\n",
    "\n",
    "    tracks_active = []\n",
    "    tracks_finished = []\n",
    "\n",
    "    for frame_num, detections_frame in enumerate(detections, start=1):\n",
    "        # apply low threshold to detections\n",
    "        # dets = [det for det in detections_frame if det['score'] >= sigma_l]\n",
    "\n",
    "        updated_tracks = []\n",
    "        for track in tracks_active:\n",
    "            if len(dets) > 0:\n",
    "                best_match_score = 0\n",
    "                best_match_index = -1\n",
    "                best_match_det = None\n",
    "                for i, detection in enumerate(dets):\n",
    "                    iou_score = compute_iou(track['bboxes'][-1], detection['bbox'])\n",
    "                    if iou_score > best_match_score:\n",
    "                        best_match_score = iou_score\n",
    "                        best_match_det = detection\n",
    "                        best_match_index = i\n",
    "                    \n",
    "                \n",
    "                if best_match_det is not None and best_match_score >= sigma_iou:\n",
    "                    track['bboxes'].append(best_match_det['bbox'])\n",
    "                    track['max_score'] = max(track['max_score'], best_match_det['score'])\n",
    "\n",
    "                    updated_tracks.append(track)\n",
    "\n",
    "                    # remove from best matching detection from detections\n",
    "                    dets = np.delete(dets, best_match_index)\n",
    "                    \n",
    "\n",
    "            # if track was not updated\n",
    "            if len(updated_tracks) == 0 or track is not updated_tracks[-1]:\n",
    "                # finish track when the conditions are met\n",
    "                if track['max_score'] >= sigma_h and len(track['bboxes']) >= t_min:\n",
    "                    tracks_finished.append(track)\n",
    "\n",
    "        # create new tracks\n",
    "        new_tracks = [{'bboxes': [det['bbox']], 'max_score': det['score'], 'start_frame': frame_num} for det in dets]\n",
    "        tracks_active = updated_tracks + new_tracks\n",
    "\n",
    "    # finish all remaining active tracks\n",
    "    tracks_finished += [track for track in tracks_active\n",
    "                        if track['max_score'] >= sigma_h and len(track['bboxes']) >= t_min]\n",
    "\n",
    "    return tracks_finished"
   ],
   "id": "6eeec0f64d5da2ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(detections_1)",
   "id": "af0b811e917adbfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "iou_tracker(detections_1, detections_2, sigma_iou=0.2)",
   "id": "b5d9bc0b5e1d8501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%timeit iou_tracker(detections_1, detections_2, sigma_iou=0.2)",
   "id": "208eb9b0911960bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detections_to_numpy_array(detections: list[tuple]) -> np.array:\n",
    "    tracks = np.zeros((len(detections), 5), dtype=np.float32)\n",
    "    for i, detection in enumerate(detections):\n",
    "        tracks[i][0] = detection[0]\n",
    "        tracks[i][1] = detection[1]\n",
    "        tracks[i][2] = detection[2]\n",
    "        tracks[i][3] = detection[3]\n",
    "        tracks[i][4] = (detection[2] - detection[0]) * (detection[3] - detection[1])\n",
    "    return tracks"
   ],
   "id": "9fdeef457924fb1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ioutrack import Sort\n",
    "\n",
    "def track_tracks_with_sort_tracker(detections: list[tuple]) -> list[BoundingBox]:\n",
    "    tracker = Sort(max_age=5, min_hits=5)\n",
    "    \n",
    "    detections_numpy = detections_to_numpy_array(detections)\n",
    "    \n",
    "    for i in range(len(detections_numpy - 1)):\n",
    "        tracker.update(detections_numpy[i])\n",
    "        \n",
    "    tracks = tracker.update(detections_numpy[len(detections_numpy) - 1])\n",
    "        \n",
    "    result = []\n",
    "    for bbox in tracks:\n",
    "        result.append(\n",
    "            BoundingBox.from_numpy(bbox)\n",
    "        )\n",
    "    return result"
   ],
   "id": "6ff630ef47990fb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_tracks(tracker, frame_1_bboxes, frame_2_bboxes):\n",
    "    tracker.update(frame_1_bboxes)\n",
    "    tracks = tracker.update(frame_2_bboxes)\n",
    "    \n",
    "    result = []\n",
    "    for bbox in tracks:\n",
    "        result.append(\n",
    "            BoundingBox.from_numpy(bbox)\n",
    "        )\n",
    "    return result"
   ],
   "id": "d26d2765c94683f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "detection_dict_1 = [{\n",
    "    'bbox': det,\n",
    "    'score': 0.2,\n",
    "} for det in detections_1]\n",
    "\n",
    "detection_dict_2 = [{\n",
    "    'bbox': det,\n",
    "    'score': 0.2,\n",
    "} for det in detections_2]\n",
    "\n",
    "tracks = track_iou(\n",
    "    detection_dict_1 + detection_dict_2,\n",
    "    sigma_l=0.01, sigma_h=1, sigma_iou=0.2, t_min=1)"
   ],
   "id": "c71391c8b20bee52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "draw_bboxes(frame2_bgr, tracks)",
   "id": "e2eafaa47860e47d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(frame2_bgr)\n",
    "plt.title(\"Non-Max Suppressed Bounding Boxes\");"
   ],
   "id": "8f12f32d4d958f28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "def save_tracks_as_images(images_directory: Path, images_extension: str) -> None:\n",
    "    image_paths = sorted(glob(f\"{images_directory}/*.{images_extension}\"),\n",
    "                         key=lambda x:float(re.findall(r\"(\\d+)\",x)[0]))\n",
    "\n",
    "    output_directory = images_directory / \"output\"\n",
    "    if output_directory.exists():\n",
    "        shutil.rmtree(str(output_directory))\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    idx = 2\n",
    "    frame1_bgr = cv2.imread(image_paths[idx - 2])\n",
    "    frame2_bgr = cv2.imread(image_paths[idx - 1])\n",
    "    \n",
    "    detections_1 = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                bbox_thresh=2,\n",
    "                                nms_thresh=1e-4)\n",
    "    while idx < len(image_paths):\n",
    "        # read frames\n",
    "        frame3_bgr = cv2.imread(image_paths[idx])\n",
    "    \n",
    "        # get detections\n",
    "        detections_2 = get_detections(cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(frame3_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                    bbox_thresh=2,\n",
    "                                    nms_thresh=1e-4)\n",
    "        \n",
    "        tracks = iou_tracker(detections_1, detections_2, sigma_iou=0.2)\n",
    "    \n",
    "    \n",
    "        # draw bounding boxes on frame\n",
    "        draw_bboxes(frame2_bgr, tracks)\n",
    "    \n",
    "        # save image for GIF\n",
    "        fig = plt.figure(figsize=(15, 7))\n",
    "        plt.imshow(frame2_bgr)\n",
    "        plt.axis('off')\n",
    "        fig.savefig(f\"{output_directory}/frame_{idx - 1}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # increment index\n",
    "        frame1_bgr = frame2_bgr\n",
    "        frame2_bgr = frame3_bgr\n",
    "        detections_1 = detections_2\n",
    "        idx += 1\n",
    "        "
   ],
   "id": "c7b0ff93957540e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def draw_detections(frame, detections: list[BoundingBox]) -> None:\n",
    "    for det in detections:\n",
    "        cv2.rectangle(frame, (det.x_min, det.y_min), (det.x_max, det.y_max), (0,255,0), 3)"
   ],
   "id": "dd0735f8a0c2e4c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def draw_tracks_on_images(image_paths: list[str], output_directory: Path) -> None:\n",
    "    tracker = Sort(max_age=5, min_hits=5)\n",
    "    \n",
    "    idx = 2\n",
    "    frame1_bgr = cv2.imread(image_paths[idx - 2])\n",
    "    frame2_bgr = cv2.imread(image_paths[idx - 1])\n",
    "    \n",
    "    detections_1 = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                bbox_thresh=128,\n",
    "                                nms_thresh=1e-3)\n",
    "    detections_1_numpy = detections_to_numpy_array(detections_1)\n",
    "    tracker.update(detections_1_numpy)\n",
    "    \n",
    "    while idx < len(image_paths):\n",
    "        # read frames\n",
    "        frame3_bgr = cv2.imread(image_paths[idx])\n",
    "    \n",
    "        # get detections\n",
    "        detections_2 = get_detections(cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(frame3_bgr, cv2.COLOR_BGR2GRAY), \n",
    "                                    bbox_thresh=128,\n",
    "                                    nms_thresh=1e-3)\n",
    "        \n",
    "        # print(f\"Between frame {idx} and frame {idx - 1} - {len(detections_2)} detections were found!\")\n",
    "    \n",
    "        detections_2_numpy = detections_to_numpy_array(detections_2)\n",
    "        tracks = tracker.update(detections_2_numpy)  \n",
    "        \n",
    "        # print(f\"On frame {idx}: {len(tracks)} tracks were found!\")\n",
    "        \n",
    "        # draw bounding boxes on frame\n",
    "        draw_tracks(frame2_bgr, tracks)\n",
    "\n",
    "        # save image for GIF\n",
    "        fig = plt.figure(figsize=(15, 7))\n",
    "        plt.imshow(frame2_bgr)\n",
    "        plt.axis('off')\n",
    "        fig.savefig(f\"{output_directory}/frame_{idx - 1}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # increment index\n",
    "        frame1_bgr = frame2_bgr\n",
    "        frame2_bgr = frame3_bgr\n",
    "        detections_1 = detections_2\n",
    "        idx += 1"
   ],
   "id": "5a24ac635d9280c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "def get_image_paths(images_dir: Path, image_extension: str) -> list[str]:\n",
    "    image_paths = sorted(glob(f\"{images_dir}/*.{image_extension}\"), \n",
    "                         key=lambda x:float(re.findall(r\"(\\d+)\",x)[0]))\n",
    "    return image_paths"
   ],
   "id": "cd910df719f97c2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "image_paths = get_image_paths(images_dir, \"png\")",
   "id": "1d82a3f41ca821db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = images_dir / \"output\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "draw_tracks_on_images(image_paths, output_directory=output_dir)"
   ],
   "id": "d3566df7e3cf3bfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_gif_from_images('frame_differencing_with_sort_tracking.gif', str(output_dir), '.png')",
   "id": "29cd1bb7dedb6db1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frame1_bgr = cv2.imread(image_paths[168])\n",
    "frame2_bgr = cv2.imread(image_paths[169])\n",
    "\n",
    "detections = get_detections(\n",
    "    cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "    cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "    bbox_thresh=128,\n",
    "    nms_thresh=1e-3,\n",
    "    mask_kernel=np.array((16,16), dtype=np.uint8)\n",
    ")\n",
    "\n",
    "draw_bboxes(frame2_bgr, detections)\n",
    "\n",
    "# save image for GIF\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.imshow(frame2_bgr)\n",
    "plt.axis('off')"
   ],
   "id": "b8dfd4d2066bd9d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(detections)",
   "id": "81f1a572f637ab5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%timeit detections = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), bbox_thresh=128, nms_thresh=1e-3, mask_kernel=np.array((9,9), dtype=np.uint8))",
   "id": "ef0ff00290648a9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pstats import Stats, SortKey\n",
    "from cProfile import Profile\n",
    "\n",
    "frame1_bgr = cv2.imread(image_paths[10])\n",
    "frame2_bgr = cv2.imread(image_paths[11])\n",
    "\n",
    "with Profile() as profile:\n",
    "    get_detections(\n",
    "        cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY), \n",
    "        cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY), \n",
    "        bbox_thresh=128,\n",
    "        nms_thresh=1e-3,\n",
    "        mask_kernel=np.array((16,16), dtype=np.uint8))\n",
    "    (\n",
    "        Stats(profile)\n",
    "        .strip_dirs()\n",
    "        .sort_stats(SortKey.CALLS)\n",
    "        .print_stats()\n",
    "    )"
   ],
   "id": "39dfed884c5f343c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
